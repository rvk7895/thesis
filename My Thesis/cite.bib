@misc{statista_internet_users_2050,
  title      = {India: number of internet users 2050},
  shorttitle = {India},
  url        = {https://www.statista.com/statistics/255146/number-of-internet-users-in-india/},
  abstract   = {In 2023, India had over 1.2 billion internet users across the country.},
  language   = {en},
  urldate    = {2023-09-09},
  journal    = {Statista}
}

@inproceedings{davidson-etal-2019-racial,
  title     = {Racial Bias in Hate Speech and Abusive Language Detection Datasets},
  author    = {Davidson, Thomas  and
               Bhattacharya, Debasmita  and
               Weber, Ingmar},
  editor    = {Roberts, Sarah T.  and
               Tetreault, Joel  and
               Prabhakaran, Vinodkumar  and
               Waseem, Zeerak},
  booktitle = {Proceedings of the Third Workshop on Abusive Language Online},
  month     = aug,
  year      = {2019},
  address   = {Florence, Italy},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/W19-3504},
  doi       = {10.18653/v1/W19-3504},
  pages     = {25--35},
  abstract  = {Technologies for abusive language detection are being developed and applied with little consideration of their potential biases. We examine racial bias in five different sets of Twitter data annotated for hate speech and abusive language. We train classifiers on these datasets and compare the predictions of these classifiers on tweets written in African-American English with those written in Standard American English. The results show evidence of systematic racial bias in all datasets, as classifiers trained on them tend to predict that tweets written in African-American English are abusive at substantially higher rates. If these abusive language detection systems are used in the field they will therefore have a disproportionate negative impact on African-American social media users. Consequently, these systems may discriminate against the groups who are often the targets of the abuse we are trying to detect.}
}

@book{rothman_hands_1987,
  title     = {Hands and {Hearts}: {A} {History} of {Courtship} in {America}},
  isbn      = {978-0-674-37160-6},
  url       = {https://books.google.co.in/books?id=FPUpAQAAMAAJ},
  publisher = {Harvard University Press},
  author    = {Rothman, E.K.},
  year      = {1987},
  lccn      = {86019575}
}

@misc{noauthor_alternative_2016,
  title      = {Alternative {Courtship}: {Matrimonial} {Advertisements} in the 19th {Century}},
  shorttitle = {Alternative {Courtship}},
  url        = {https://www.mimimatthews.com/2016/01/04/alternative-courtship-matrimonial-advertisements-in-the-19th-century/},
  abstract   = {For some in the 19th century, placing a matrimonial advertisement in a local newspaper was considered a viable alternative to traditional courtship.},
  language   = {en},
  urldate    = {2024-03-02},
  journal    = {Mimi Matthews},
  month      = jan,
  year       = {2016},
  note       = {Section: 19th Century},
  file       = {Snapshot:C\:\\Users\\rkal2\\Zotero\\storage\\IJ458529\\alternative-courtship-matrimonial-advertisements-in-the-19th-century.html:text/html}
}

@misc{markarian_how_2017,
  title    = {How {Dating} {Has} {Changed} {Over} {The} {Last} 100 {Years}},
  url      = {https://www.thelist.com/62575/dating-changed-last-100-years/},
  abstract = {From the turn of the 20th century, to the present day, romantic relationships have been an evolving part of culture, just like everything else!},
  language = {en-US},
  urldate  = {2024-03-02},
  journal  = {The List},
  author   = {Markarian, Taylor},
  month    = may,
  year     = {2017},
  file     = {Snapshot:C\:\\Users\\rkal2\\Zotero\\storage\\THPNDLKL\\dating-changed-last-100-years.html:text/html}
}

@misc{magazine_mechanical_nodate,
  title      = {Mechanical {Matchmaking}: {The} {Science} of {Love} in the 1920s},
  shorttitle = {Mechanical {Matchmaking}},
  url        = {https://www.smithsonianmag.com/history/mechanical-matchmaking-the-science-of-love-in-the-1920s-103877403/},
  abstract   = {Four "scientific" tests to determine whether your marriage will succeed or fail},
  language   = {en},
  urldate    = {2024-03-02},
  journal    = {Smithsonian Magazine},
  author     = {Magazine, Smithsonian and Novak, Matt},
  note       = {Section: History, U.S. History, , Blogs, , Paleofuture, , Articles},
  file       = {Snapshot:C\:\\Users\\rkal2\\Zotero\\storage\\JSI8YLRB\\mechanical-matchmaking-the-science-of-love-in-the-1920s-103877403.html:text/html}
}

@misc{newark_introduction_nodate,
  title      = {A brief history of online dating: Tinder swipe life},
  shorttitle = {A brief history of online dating},
  language   = {en},
  urldate    = {2020-07-05},
  author     = {K.C. Jackson}
}

@misc{noauthor_operation_1965,
  title    = {Operation {Match} {\textbar} {News} {\textbar} {The} {Harvard} {Crimson}},
  url      = {https://www.thecrimson.com/article/1965/11/3/operation-match-pif-you-stop-to/},
  abstract = {If you stop to talk to Jeff Tarr, Dave Crump, or Doug Ginsberg for a few minutes, you'll find them},
  urldate  = {2024-03-03},
  month    = nov,
  year     = {1965},
  file     = {Snapshot:C\:\\Users\\rkal2\\Zotero\\storage\\ZQ3S3R6S\\operation-match-pif-you-stop-to.html:text/html}
}


@misc{valley_new_2015,
  title    = {New dating apps cut to the chase, set up dates quickly},
  url      = {https://www.latimes.com/business/la-fi-dating-apps-20150129-story.html},
  abstract = {Tedious, frustrating, emotionally draining — that's how Eve Peters felt about online dating after seven years in the industry.},
  language = {en-US},
  urldate  = {2024-03-03},
  journal  = {Los Angeles Times},
  author   = {Tracey Lien},
  month    = jan,
  year     = {2015},
  note     = {Section: Business},
  file     = {Snapshot:C\:\\Users\\rkal2\\Zotero\\storage\\2IPC8ZCU\\la-fi-dating-apps-20150129-story.html:text/html}
}

@book{book:1309549,
  title     = {Sex in Development: Science, Sexuality, and Morality in Global Perspective},
  author    = {Vincanne Adams, Stacy Leigh Pigg},
  publisher = {Duke University Press Books},
  isbn      = {0822334798,9780822334798},
  year      = {2005},
  series    = {},
  edition   = {},
  volume    = {},
  url       = {http://gen.lib.rus.ec/book/index.php?md5=e5806cd00caa8fa664501909c070c07f}
}


@misc{waters_how_2021,
  title    = {How 1970s {VCR} dating paved the way for {Tinder} and {Hinge}},
  url      = {https://www.vox.com/22262353/great-expectations-history-video-dating-vcr-apps},
  abstract = {Great Expectations, which existed into the ’90s, was the original dating technology.},
  language = {en},
  urldate  = {2024-03-30},
  journal  = {Vox},
  author   = {Waters, Michael},
  month    = feb,
  year     = {2021},
  file     = {Snapshot:C\:\\Users\\rkal2\\Zotero\\storage\\WRZF6MIV\\great-expectations-history-video-dating-vcr-apps.html:text/html}
}


@misc{noauthor_dating_nodate,
  title   = {Dating through the ages: {How} matchmaking evolved with technology - {Hindustan} {Times}},
  url     = {https://www.hindustantimes.com/sex-and-relationships/dating-through-the-ages-how-matchmaking-evolved-with-technology/story-RnfIOP8p2VJLqlU6Nq3MXK.html},
  urldate = {2024-03-30},
  file    = {Dating through the ages\: How matchmaking evolved with technology - Hindustan Times:C\:\\Users\\rkal2\\Zotero\\storage\\8UURNF9R\\story-RnfIOP8p2VJLqlU6Nq3MXK.html:text/html}
}

@inproceedings{marcus2016swipe,
  title     = {Swipe to the right”: Assessing self-presentation in the context of mobile dating applications},
  author    = {Marcus, Sarah Rose},
  booktitle = {Annual Conference of the International Communication Association (ICA), Fukuoka, Japan},
  pages     = {9--13},
  year      = {2016}
}


@article{doshi_date_2016,
  chapter  = {World news},
  title    = {Date, kiss or marry ... how {Tinder} is rewriting {India}’s rules of engagement},
  issn     = {0029-7712},
  url      = {https://www.theguardian.com/world/2016/jul/09/india-love-revolution-dating-fun-arranged-marriage-apps-tinder},
  abstract = {In a country where casual relationships are still frowned on, young Indians are defying parents and society by using smartphone apps to meet partners},
  language = {en-GB},
  urldate  = {2024-04-05},
  journal  = {The Observer},
  author   = {Doshi, Vidhi},
  month    = jul,
  year     = {2016},
  keywords = {Dating, India, Life and style, South and central Asia, Technology, Tinder, World news},
  file     = {Snapshot:C\:\\Users\\rkal2\\Zotero\\storage\\QMNSMUJX\\india-love-revolution-dating-fun-arranged-marriage-apps-tinder.html:text/html}
}

@article{noauthor_modern_2017,
  title    = {The modern rules of dating},
  issn     = {0971-8257},
  url      = {https://timesofindia.indiatimes.com/life-style/relationships/love-sex/the-modern-rules-of-dating/articleshow/18428145.cms},
  abstract = {The current generation is subverting the traditional rules of courtship. So, hook-up is the new dating and marriage is no longer the goal.},
  urldate  = {2024-04-05},
  journal  = {The Times of India},
  month    = nov,
  year     = {2017},
  file     = {Snapshot:C\:\\Users\\rkal2\\Zotero\\storage\\C3JXRXYC\\18428145.html:text/html}
}

@inproceedings{sharma_towards_2019,
  address    = {Berlin, Heidelberg},
  title      = {Towards {Safe} {Spaces} {Online}: {A} {Study} of {Indian} {Matrimonial} {Websites}},
  isbn       = {978-3-030-29386-4},
  shorttitle = {Towards {Safe} {Spaces} {Online}},
  url        = {https://doi.org/10.1007/978-3-030-29387-1_4},
  doi        = {10.1007/978-3-030-29387-1_4},
  abstract   = {We studied Indian matrimonial websites that facilitate arranged marriages, focusing on how they are designed to foster safety and inclusivity. We conducted 20 interviews with marriage seekers and parents to understand how they use the sites. We examined government policy, technical affordances, human services, and the presence of the social network. We contrast matrimonial sites to dating websites in the Indian context. Matrimonial websites’ affordances suggest ways we might make other kinds of sites safer.},
  urldate    = {2024-04-05},
  booktitle  = {Human-{Computer} {Interaction} – {INTERACT} 2019: 17th {IFIP} {TC} 13 {International} {Conference}, {Paphos}, {Cyprus}, {September} 2–6, 2019, {Proceedings}, {Part} {III}},
  publisher  = {Springer-Verlag},
  author     = {Sharma, Vishal and Nardi, Bonnie and Norton, Juliet and Tsaasan, A. M.},
  month      = sep,
  year       = {2019},
  keywords   = {Arranged marriage, Computer-mediated communication, Inclusion, India, Marginalized communities, Matrimonial sites, Safe spaces, Safety},
  pages      = {43--66},
  file       = {Submitted Version:C\:\\Users\\rkal2\\Zotero\\storage\\56T8VA76\\Sharma et al. - 2019 - Towards Safe Spaces Online A Study of Indian Matr.pdf:application/pdf}
}

@article{seth_online_2008,
  title    = {Online {Matrimonial} {Sites} and the {Transformation} of {Arranged} {Marriage} in {India}},
  issn     = {9781605661056},
  doi      = {10.4018/978-1-60566-104-9.ch019},
  abstract = {AbstrAct Online personals have been a remarkably successful in the Western World and have been emulated in other cultural contexts. The introduction of the Internet can have vastly different implications on traditional societies and practices such as arranged marriages in India. This chapter seeks to investigate using an ethnographic approach the role of matrimonial Web sites in the process of arranging marriages in India. It seeks to explore how these Web sites have been appropriated by key stakeholders in arranging marriage and how such appropriation is changing the process and traditions associated with arranged marriage. The key contributions of this study are in that it is an investigation of complex social processes in a societal context different from traditional western research contexts and an exploration of how mod-ern technologies confront societal traditions and long standing ways of doing things. Our investigation suggests that the use of matrimonial Web sites have implications for family disintermediation, cultural convergence, continuous information flows, ease of disengagement, virtual dating and reduced stigma in arranged marriages in India.},
  journal  = {Social Networking Communities and E-Dating Services: Concepts and Implications},
  author   = {Seth, Nainika and Patnayakuni, Ravi},
  month    = jan,
  year     = {2008},
  file     = {Full Text PDF:C\:\\Users\\rkal2\\Zotero\\storage\\5SZNW54A\\Seth and Patnayakuni - 2008 - Online Matrimonial Sites and the Transformation of.pdf:application/pdf}
}

@article{titzmann_changing_2013,
  title      = {Changing {Patterns} of {Matchmaking}: {The} {Indian} {Online} {Matrimonial} {Market}},
  volume     = {19},
  shorttitle = {Changing {Patterns} of {Matchmaking}},
  doi        = {10.1080/12259276.2013.11666166},
  abstract   = {Indian matrimonial websites, as a new and popular medium for seeking marriage partners, have millions of users and have become increasingly important in India's marriage market as of the late 1990s. Despite their traditional approach, evident in their structure and design, these online spaces nevertheless reflect new dimensions of media usage and choice of partners. They show the active intervention of people in their own future planning. By assuming a basic connection between the growing media access and profound changes within contemporary Indian society, this article links media-based changes in matchmaking to an overall social change in post-liberalization India. With new lifestyles and social realities, notions regarding marriage, love, and gender roles are gradually being reworked. The analysis of the online matrimonial market and how it has been appropriated, offers remarkable insights into these dimensions of social change. Ninety percent of India's marriages are still termed as arranged, as opposed to the category of love marriage. But the varied ways in which many young Indians engage with matrimonial media show that this dichotomy of terms needs urgent revision. Increasing social, physical, and media mobilities serve in manifold ways as a key factor in social change, particularly with regard to women and marriage. The pervasive gender image of the New Indian Woman is an influential role model in online representations as well as in personal narratives. She rambines a modem lifestyle with cultural rootedness and makes way for new forms of subjectivity and agency. In the context of changing patterns and concepts, the ideological difference between agency and choice with regard to decision-making in matchmaking emerges as another crucial point for discussion. While agency emphasizes the capacity to act, choice is connoted by a consumerist viewpoint. But the explicitly new aspect about a medialised marriage market is the progressively interactive nature of online matrimonial media.},
  journal    = {Asian Journal of Women's Studies},
  author     = {Titzmann, Fritzi-Marie},
  month      = jan,
  year       = {2013},
  pages      = {64--94}
}

@misc{noauthor_india_nodate,
  title      = {India: number of internet users 2050},
  shorttitle = {India},
  url        = {https://www.statista.com/statistics/255146/number-of-internet-users-in-india/},
  abstract   = {In 2023, India had over 1.2 billion internet users across the country.},
  language   = {en},
  urldate    = {2024-03-30},
  journal    = {Statista},
  file       = {Snapshot:C\:\\Users\\rkal2\\Zotero\\storage\\JUHLXSAT\\number-of-internet-users-in-india.html:text/html}
}

@misc{noauthor_bumble_nodate,
  title    = {Bumble 101},
  url      = {https://gew3.bumble.com/en-in/help/bumble-101},
  abstract = {Bumble has changed the way people date, create meaningful relationships \& network with women making the first move. Meet new people \& download Bumble.},
  language = {en},
  urldate  = {2024-04-07},
  journal  = {Bumble},
  file     = {Snapshot:C\:\\Users\\rkal2\\Zotero\\storage\\VSBNARFV\\bumble-101.html:text/html}
}

 @article{Raghavan_Barocas_Kleinberg_Levy_2019,
  address      = {Rochester, NY},
  type         = {SSRN Scholarly Paper},
  title        = {Mitigating Bias in Algorithmic Hiring: Evaluating Claims and Practices},
  url          = {https://papers.ssrn.com/abstract=3408010},
  doi          = {10.2139/ssrn.3408010},
  abstractnote = {There has been rapidly growing interest in the use of algorithms in hiring, especially as a means to address or mitigate bias. Yet, to date, little is known about how these methods are used in practice. How are algorithmic assessments built, validated, and examined for bias? In this work, we document and analyze the claims and practices of companies offering algorithms for employment assessment. In particular, we identify vendors of algorithmic pre-employment assessments (i.e., algorithms to screen candidates), document what they have disclosed about their development and validation procedures, and evaluate their practices, focusing particularly on efforts to detect and mitigate bias. Our analysis considers both technical and legal perspectives. Technically, we consider the various choices vendors make regarding data collection and prediction targets, and explore the risks and trade-offs that these choices pose. We also discuss how algorithmic de-biasing techniques interface with, and create challenges for, antidiscrimination law.},
  number       = {3408010},
  author       = {Raghavan, Manish and Barocas, Solon and Kleinberg, Jon and Levy, Karen},
  year         = {2019},
  month        = jun,
  language     = {en}
}

 @article{Bivens_Hoque_2018,
  title        = {Programming Sex, Gender, and Sexuality: Infrastructural Failures in ‘Feminist’ Dating App Bumble},
  volume       = {43},
  doi          = {10.22230/cjc.2019v44n3a3375},
  abstractnote = {Background
                  Bumble is a self-declared “feminist” dating app that gives women control over initiating conversations with potential matches.
                  
                  Analysis
                  Through a material-semiotic analysis of Bumble’s software and online media about the app, this article critically investigates how gender, sex, and sexuality are produced and given meaning by Bumble’s programmed infrastructure.
                  
                  Conclusions and implications
                  Since the epistemological underpinnings of Bumble’s design centre gender as the solitary axis of oppression, the authors argue that the app’s infrastructure generates an ontological relationship between gender, sex, and sexuality that narrows the capacity to achieve its creators’ stated social justice objectives. Several infrastructural failures are detailed to demonstrate how control and safety are 1) optimized for straight cisgender women, and 2) contingent on the inscription of an aggressive form of masculinity onto straight male bodies.
                  
                  RÉSUMÉ
                  
                  Contexte
                  Bumble est une application de rencontres prétendument « féministe » qui donne aux femmes le pouvoir d’initier des conversations avec des compagnons potentiels.
                  
                  Analyse
                  Cet article effectue une analyse sémiotique matérielle de Bumble et de commentaires en ligne sur cette application dans le but d’examiner comment l’infrastructure programmée de Bumble produit le genre, le sexe et la sexualité et leur donne du sens.
                  
                  Conclusions et implications
                  Bumble a une perspective épistémologique selon laquelle le genre est la seule source d’oppression. Or, d’après les auteurs, ce point de vue encourage un rapport ontologique entre genre, sexe et sexualité qui entrave la capacité des créateurs à atteindre leurs objectifs de justice sociale. Cet article recense plusieurs échecs infrastructurels de l’application afin de montrer comment le contrôle et la sécurité 1) conviennent principalement aux femmes cisgenres hétérosexuelles et 2) supposent une masculinité agressive inscrite sur des corps mâles hétérosexuels.},
  author       = {Bivens, Rena and Hoque, Anna},
  year         = {2018},
  month        = aug
}

@article{MacLeod_McArthur_2019,
  title        = {The construction of gender in dating apps: an interface analysis of Tinder and Bumble},
  volume       = {19},
  issn         = {1468-0777},
  doi          = {10.1080/14680777.2018.1494618},
  abstractnote = {In this article, we analyse two mobile dating applications: Tinder and Bumble. Mobilizing two studies by Erving Goffman and Lucille Alice Suchman, we present a detailed analysis of the affordances of the profile creation tools of both of these applications. Together, these theoretical perspectives make visible the effect that the constraints imposed by the app’s self-presentation tools have on constructing subjects that are intelligible to the apps’ algorithms and, by implication, its designers and other users. Specifically, through our analysis, we demonstrate how the gender categories made available to users in creating their profiles are reflective of the structural needs of the app’s programming. This work is motivated by two research questions: First, how do the affordances of digital communication tools structure their users’ identities as they are both constructed and performed through the technology? Second, in what ways are notions of gender reflected in the affordances of mobile dating applications’ profile creation tools? Our results indicate that these apps construct gender as a rigid category that has more to do with function (matching profiles) than with identity. Implications for identity and design are discussed.},
  number       = {6},
  journal      = {Feminist Media Studies},
  publisher    = {Routledge},
  author       = {MacLeod, Caitlin and McArthur, Victoria},
  year         = {2019},
  month        = aug,
  pages        = {822–840}
}

@misc{Carr_2016,
  title        = {I Found Out My Secret Internal Tinder Rating And Now I Wish I Hadn’t},
  url          = {https://www.fastcompany.com/3054871/whats-your-tinder-score-inside-the-apps-internal-ranking-system},
  abstractnote = {The dating app uses data to give every user a desirability rating. Here’s how it works—and what happened when I discovered my number.},
  journal      = {Fast Company},
  author       = {Carr, Austin},
  year         = {2016},
  month        = jan
}

@inbook{Das_2019,
  series       = {Perspectives from South Asia},
  title        = {Dating Applications, Intimacy, and Cosmopolitan Desire in India},
  isbn         = {978-0-472-13140-2},
  url          = {https://www.jstor.org/stable/j.ctvndv9rb.9},
  abstractnote = {On October 8, 2015, TrulyMadly Matchmakers Private Ltd. cemented its presence as a key player in India’s mobile-phone-based dating app market by releasing a digital advertisement that went viral. The video, titled “Creep Qawwali”, opened with two troupes of female  qawwali ¹ singers sitting on the floor, facing each other, in an ornate room replete with chandeliers, candelabras, fairy lights, and flower arrangements. The title briefly superimposed on this scene included cartoon hearts, a tabla,² and a bearded caricature of what I was told was a “stereotypically creepy” man with wide leering eyes and a curly beard.³ In the advertisement, the},
  booktitle    = {Global Digital Cultures},
  publisher    = {University of Michigan Press},
  author       = {Das, Vishnupriya},
  editor       = {Punathambekar, Aswin and Mohan, Sriram},
  year         = {2019},
  pages        = {125–141},
  collection   = {Perspectives from South Asia}
}

@misc{Forbes_2020,
  title        = {How Homegrown Dating Apps Are Finding Love In India},
  url          = {https://www.forbesindia.com/article/local-champ-2020/how-homegrown-dating-apps-are-finding-love-in-india/65155/1},
  abstractnote = {Leveraging their intrinsic knowledge of Indian culture and social norms, homegrown dating apps are gaining an edge over foreign counterparts, positioning themselves as means to look for longer-term relationships--and not casual dating--to carve out a market share},
  journal      = {Forbes India},
  author       = {Forbes},
  year         = {2020},
  month        = dec,
  language     = {en}
}

 @article{Hutson_Taft_Barocas_Levy_2018,
  address      = {Rochester, NY},
  type         = {SSRN Scholarly Paper},
  title        = {Debiasing Desire: Addressing Bias and Discrimination on Intimate Platforms},
  url          = {https://papers.ssrn.com/abstract=3244459},
  abstractnote = {Designing technical systems to be resistant to bias and discrimination represents vital new terrain for researchers, policymakers, and the anti-discrimination project more broadly. We consider bias and discrimination in the context of popular online dating and hookup platforms in the United States, which we call “intimate platforms.” Drawing on work in social-justice-oriented and Queer HCI, we review design features of popular intimate platforms and their potential role in exacerbating or mitigating interpersonal bias. We argue that focusing on platform design can reveal opportunities to reshape troubling patterns of intimate contact without overriding users’ decisional autonomy. We identify and address the difficult ethical questions that nevertheless come along with such intervention, while urging the social computing community to engage more deeply with issues of bias, discrimination, and exclusion in the study and design of intimate platforms.},
  number       = {3244459},
  author       = {Hutson, Jevan and Taft, Jessie and Barocas, Solon and Levy, Karen},
  year         = {2018},
  month        = sep,
  language     = {en}
}
 @article{Lambrecht_Tucker_2019,
  title        = {Algorithmic Bias? An Empirical Study of Apparent Gender-Based Discrimination in the Display of STEM Career Ads},
  volume       = {65},
  issn         = {0025-1909, 1526-5501},
  doi          = {10.1287/mnsc.2018.3093},
  abstractnote = {We explore data from a field test of how an algorithm delivered ads promoting job opportunities in the science, technology, engineering and math fields. This ad was explicitly intended to be gender neutral in its delivery. Empirically, however, fewer women saw the ad than men. This happened because younger women are a prized demographic and are more expensive to show ads to. An algorithm that simply optimizes cost-effectiveness in ad delivery will deliver ads that were intended to be gender neutral in an apparently discriminatory way, because of crowding out. We show that this empirical regularity extends to other major digital platforms.
                  This paper was accepted by Joshua Gans, business strategy.},
  number       = {7},
  journal      = {Management Science},
  author       = {Lambrecht, Anja and Tucker, Catherine},
  year         = {2019},
  month        = jul,
  pages        = {2966–2981},
  language     = {en}
}
 @inproceedings{Selbst_Boyd_Friedler_Venkatasubramanian_Vertesi_2019,
  address      = {Atlanta GA USA},
  title        = {Fairness and Abstraction in Sociotechnical Systems},
  isbn         = {978-1-4503-6125-5},
  url          = {https://dl.acm.org/doi/10.1145/3287560.3287598},
  doi          = {10.1145/3287560.3287598},
  abstractnote = {A key goal of the fair-ML community is to develop machine-learning based systems that, once introduced into a social context, can achieve social and legal outcomes such as fairness, justice, and due process. Bedrock concepts in computer science—such as abstraction and modular design—are used to define notions of fairness and discrimination, to produce fairness-aware learning algorithms, and to intervene at different stages of a decision-making pipeline to produce “fair” outcomes. In this paper, however, we contend that these concepts render technical interventions ineffective, inaccurate, and sometimes dangerously misguided when they enter the societal context that surrounds decision-making systems. We outline this mismatch with five “traps” that fair-ML work can fall into even as it attempts to be more context-aware in comparison to traditional data science. We draw on studies of sociotechnical systems in Science and Technology Studies to explain why such traps occur and how to avoid them. Finally, we suggest ways in which technical designers can mitigate the traps through a refocusing of design in terms of process rather than solutions, and by drawing abstraction boundaries to include social actors rather than purely technical ones.},
  booktitle    = {Proceedings of the Conference on Fairness, Accountability, and Transparency},
  publisher    = {ACM},
  author       = {Selbst, Andrew D. and Boyd, Danah and Friedler, Sorelle A. and Venkatasubramanian, Suresh and Vertesi, Janet},
  year         = {2019},
  month        = jan,
  pages        = {59–68},
  language     = {en}
}

 @article{Kalra_Gupta_Varghese_Rangaswamy_2023,
  title        = {Exploring Gender Disparities in Bumble’s Match Recommendations},
  url          = {http://arxiv.org/abs/2312.09626},
  doi          = {10.48550/arXiv.2312.09626},
  abstractnote = {We study bias and discrimination in the context of Bumble, an online dating platform in India. Drawing on research in AI fairness and inclusion studies we analyze algorithmic bias and their propensity to reproduce bias. We conducted an experiment to identify and address the presence of bias in the matching algorithms Bumble pushes to its users in the form of profiles for potential dates in the real world. Dating apps like Bumble utilize algorithms that learn from user data to make recommendations. Even if the algorithm does not have intentions or consciousness, it is a system created and maintained by humans. We attribute moral agency of such systems to be compositely derived from algorithmic mediations, the design and utilization of these platforms. Developers, designers, and operators of dating platforms thus have a moral obligation to mitigate biases in the algorithms to create inclusive platforms that affirm diverse social identities.},
  note         = {arXiv:2312.09626 [cs]},
  number       = {arXiv:2312.09626},
  publisher    = {arXiv},
  author       = {Kalra, Ritvik Aryan and Gupta, Pratham and Varghese, Ben and Rangaswamy, Nimmi},
  year         = {2023},
  month        = dec
}

@article{Dell_2005,
  title        = {“Ordinary” Sex, Prostitutes, and Middle-Class Wives: Liberalization and National Identity in India},
  url          = {https://read.dukeupress.edu/books/book/938/chapter/145443/Ordinary-Sex-Prostitutes-and-Middle-Class},
  doi          = {10.1215/9780822386414-009},
  abstractnote = {not for saleReferencesAbramson, Paul R., and PinkertonSteven D.. 1995. “Introduction: Nature, Nurture, and In-Between.” In Sexual Nature/Sexual Culture, ed. Abr},
  author       = {Dell, Heather S.},
  year         = {2005},
  month        = apr,
  language     = {en}
}
@misc{HindustanTimes_2020,
  title        = {Bumble hits 4 million users in India, women continue to make the first move},
  url          = {https://tech.hindustantimes.com/tech/news/bumble-hits-4-million-users-in-india-women-continue-to-make-the-first-move-71596094558381.html},
  abstractnote = {Women in India are also sending twice the number of messages on Bumble as compared to users globally.},
  journal      = {HT Tech},
  author       = {HindustanTimes},
  year         = {2020},
  month        = jul,
  language     = {en}
}

 @misc{Chronicle_2023,
  title    = {Bumble’s Love Unfiltered Report 2023 Findings},
  url      = {https://www.deccanchronicle.com/lifestyle/sex-and-relationship/010923/how-does-social-media-and-its-trends-impact-genz-dating-ideals.html},
  journal  = {Deccan Chronicle},
  author   = {Chronicle, Deccan},
  year     = {2023},
  month    = sep,
  language = {en}
}
 @misc{MediaInfoline_2021,
  title        = {Bumble Shows How Single Indians Are Planning To Date in 2021},
  url          = {https://www.mediainfoline.com/article/bumble-shows-how-single-indians-are-planning-to-date-in-2021},
  abstractnote = {Bumble shows how single Indians are changing in favour of virtual dates and predates to build trust online as the dating scene unlocks},
  journal      = {Media Infoline},
  author       = {MediaInfoline},
  year         = {2021},
  month        = jan,
  language     = {en-US}
}
 @misc{Smith_2016,
  title        = {15% of American Adults Have Used Online Dating Sites or Mobile Dating Apps},
  url          = {https://www.pewresearch.org/internet/2016/02/11/15-percent-of-american-adults-have-used-online-dating-sites-or-mobile-dating-apps/},
  abstractnote = {The share of 18- to 24-year-olds who report using online dating has nearly tripled in the past two years, while usage among 55- to 64-year-olds has doubled.},
  journal      = {Pew Research Center: Internet, Science & Tech},
  author       = {Smith, Aaron},
  year         = {2016},
  month        = feb,
  language     = {en-US}
}

@article{Johar,
  title    = {IN THE SUPREME COURT OF INDIA CRIMINAL ORIGINAL JURISDICTION WRIT PETITION (CRIMINAL) NO. 77 OF 2016},
  author   = {Johar, Navtej Singh},
  language = {en}
}
@misc{Bumble,
  title        = {Bumble - Bumble India’s Healthy Queer Dating Guide for LGBTQ+ Communities},
  url          = {https://bumble.com/the-buzz/bumble-india-healthy-queer-dating-guide-for-lgbtq-communities},
  abstractnote = {Bumble teamed up with LGTBQ+ experts in India to create a Healthy Queer Dating Guide to support kind, equitable relationships for everyone.},
  journal      = {Bumble Buzz},
  author       = {Bumble},
  language     = {en-us}
}

 @misc{Bumble_incognito,
  title        = {Bumble - What is Incognito Mode and How to Use Incognito Mode for a Better Bumble Experience},
  url          = {https://bumble.com/the-buzz/bumble-incognito-mode},
  abstractnote = {Everything you need to know about Bumble’s Incognito Mode feature, from how to activate it to what the benefits are.},
  journal      = {Bumble Buzz},
  author       = {Bumble},
  language     = {en-in}
}

@misc{Bumble_private_detector,
  title        = {What is Private Detector and how does it work?},
  url          = {https://bumble.com/en-in/help/what-is-private-detector},
  abstractnote = {Bumble has changed the way people date, create meaningful relationships & network with women making the first move. Meet new people & download Bumble.},
  journal      = {Bumble},
  author       = {Bumble},
  language     = {en}
}

@misc{Bumble_photo_verification,
  title        = {Photo Verification},
  url          = {https://bumble.com/en-us/help/how-can-i-verify-my-profile},
  abstractnote = {Bumble has changed the way people date, create meaningful relationships & network with women making the first move. Meet new people & download Bumble.},
  journal      = {Bumble},
  author       = {Bumble},
  language     = {en}
}

@misc{Bumble_pronoun_feature,
  title  = {Bumble - Here Are Bumble’s Inclusive Gender Identity Options -},
  url    = {https://bumble.com/en-in/the-buzz/bumble-gender-options},
  author = {Bumble}
}

@article{Blackwell_2015,
  author   = {Courtney Blackwell and Jeremy Birnholtz and Charles Abbott},
  title    = {Seeing and being seen: Co-situation and impression formation using Grindr, a location-aware gay dating app},
  journal  = {New Media \& Society},
  volume   = {17},
  number   = {7},
  pages    = {1117-1136},
  year     = {2015},
  doi      = {10.1177/1461444814521595},
  url      = {https://doi.org/10.1177/1461444814521595},
  eprint   = {https://doi.org/10.1177/1461444814521595},
  abstract = {While online spaces and communities were once seen to transcend geography, the ubiquity of location-aware mobile devices means that today’s online interactions are deeply intertwined with offline places and relationships. Systems such as online dating applications for meeting nearby others provide novel social opportunities, but can also complicate interaction by aggregating or “co-situating” diverse sets of individuals. Often this aggregation occurs across traditional spatial or community boundaries that serve as cues for self-presentation and impression formation. This paper explores these issues through an interview study of Grindr users. Grindr is a location-aware real-time dating application for men who have sex with men. We argue that co-situation affects how and whether Grindr users and their behavior are visible to others, collapses or erases contextual cues about normative behavior, and introduces tensions in users’ self-presentation in terms of their identifiability and the cues their profile contains relative to their behavior. }
}

@misc{Publishers_Distributors4753/23_Road_Delhi,
  title        = {Digital Queer Cultures in India: Politics, Intimacies and Belonging},
  url          = {https://www.routledge.com/Digital-Queer-Cultures-in-India-Politics-Intimacies-and-Belonging/Dasgupta/p/book/9780367279882},
  abstractnote = {Sexuality in India offers an expression of nationalist anxieties and is a significant marker of modernity through which subjectivities are formed among the middle class. This book investigates the everyday experience of queer Indian men on digital spaces. It explores how queer identities are formed in virtual spaces and how the existence of such spaces challenge and critique ‘Indian’-ness. It also looks at the role of class and intimacy within the discourse. This work argues that new media,},
  journal      = {Routledge & CRC Press},
  author       = {Publishers, Manohar and Distributors4753/23 and Road, Ansari and Delhi 110 002, DaryaganjNew},
  language     = {en}
}

@misc{Mattu_COMPAS,
  title        = {How We Analyzed the COMPAS Recidivism Algorithm},
  url          = {https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm},
  abstractnote = {ProPublica is an independent, non-profit newsroom that produces investigative journalism in the public interest.},
  journal      = {ProPublica},
  author       = {Mattu and Jeff Larson and Julia Angwin and Lauren Kirchner and Surya},
  language     = {en}
}

@article{Bartlett_Morse_Stanton_Wallace_2022,
  title        = {Consumer-lending discrimination in the FinTech Era},
  volume       = {143},
  issn         = {0304-405X},
  doi          = {10.1016/j.jfineco.2021.05.047},
  abstractnote = {U.S. fair-lending law prohibits lenders from making credit determinations that disparately affect minority borrowers if those determinations are based on characteristics unrelated to creditworthiness. Using an identification under this rule, we show risk-equivalent Latinx/Black borrowers pay significantly higher interest rates on GSE-securitized and FHA-insured loans, particularly in high-minority-share neighborhoods. We estimate these rate differences cost minority borrowers over $450 million yearly. FinTech lenders’ rate disparities were similar to those of non-Fintech lenders for GSE mortgages, but lower for FHA mortgages issued in 2009–2015 and for FHA refi mortgages issued in 2018–2019.},
  number       = {1},
  journal      = {Journal of Financial Economics},
  author       = {Bartlett, Robert and Morse, Adair and Stanton, Richard and Wallace, Nancy},
  year         = {2022},
  month        = jan,
  pages        = {30–56}
}

@inproceedings{Buolamwini_Gebru_2018,
  title        = {Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification},
  issn         = {2640-3498},
  url          = {https://proceedings.mlr.press/v81/buolamwini18a.html},
  abstractnote = {Recent studies demonstrate that machine learning algorithms can discriminate based on classes like race and gender. In this work, we present an approach to evaluate bias present in automated facial analysis algorithms and datasets with respect to phenotypic subgroups. Using the dermatologist  approved Fitzpatrick Skin Type classification system, we characterize the gender and skin type distribution of two facial analysis benchmarks, IJB-A and Adience. We find that these datasets are overwhelmingly composed of lighter-skinned subjects (79.6% for IJB-A and 86.2% for Adience) and introduce a new facial analysis dataset which is balanced by gender and skin type. We evaluate 3 commercial gender classification systems using our dataset and show that darker-skinned females are the most misclassified group (with error rates of up to 34.7%). The maximum error rate for lighter-skinned males is 0.8%. The substantial disparities in the accuracy of classifying darker females, lighter females, darker males, and lighter males in gender classification systems require urgent attention if commercial companies are to build genuinely fair, transparent and accountable facial analysis algorithms.},
  booktitle    = {Proceedings of the 1st Conference on Fairness, Accountability and Transparency},
  publisher    = {PMLR},
  author       = {Buolamwini, Joy and Gebru, Timnit},
  year         = {2018},
  month        = jan,
  pages        = {77–91},
  language     = {en}
}

@article{Obermeyer_Powers_Vogeli_Mullainathan_2019,
  title        = {Dissecting racial bias in an algorithm used to manage the health of populations},
  volume       = {366},
  issn         = {1095-9203},
  doi          = {10.1126/science.aax2342},
  abstractnote = {Health systems rely on commercial prediction algorithms to identify and help patients with complex health needs. We show that a widely used algorithm, typical of this industry-wide approach and affecting millions of patients, exhibits significant racial bias: At a given risk score, Black patients are considerably sicker than White patients, as evidenced by signs of uncontrolled illnesses. Remedying this disparity would increase the percentage of Black patients receiving additional help from 17.7 to 46.5%. The bias arises because the algorithm predicts health care costs rather than illness, but unequal access to care means that we spend less money caring for Black patients than for White patients. Thus, despite health care cost appearing to be an effective proxy for health by some measures of predictive accuracy, large racial biases arise. We suggest that the choice of convenient, seemingly effective proxies for ground truth can be an important source of algorithmic bias in many contexts.},
  number       = {6464},
  journal      = {Science (New York, N.Y.)},
  author       = {Obermeyer, Ziad and Powers, Brian and Vogeli, Christine and Mullainathan, Sendhil},
  year         = {2019},
  month        = oct,
  pages        = {447–453},
  language     = {eng}
}

@inproceedings{Lahoti_Gummadi_Weikum_2019,
  title        = {iFair: Learning Individually Fair Data Representations for Algorithmic Decision Making},
  issn         = {2375-026X},
  doi          = {10.1109/ICDE.2019.00121},
  abstractnote = {People are rated and ranked, towards algorithmic decision making in an increasing number of applications, typically based on machine learning. Research on how to incorporate fairness into such tasks has prevalently pursued the paradigm of group fairness: giving adequate success rates to specifically protected groups. In contrast, the alternative paradigm of individual fairness has received relatively little attention, and this paper advances this less explored direction. The paper introduces a method for probabilistically mapping user records into a low-rank representation that reconciles individual fairness and the utility of classifiers and rankings in downstream applications. Our notion of individual fairness requires that users who are similar in all task-relevant attributes such as job qualification, and disregarding all potentially discriminating attributes such as gender, should have similar outcomes. We demonstrate the versatility of our method by applying it to classification and learning-to-rank tasks on a variety of real-world datasets. Our experiments show substantial improvements over the best prior work for this setting.},
  booktitle    = {2019 IEEE 35th International Conference on Data Engineering (ICDE)},
  author       = {Lahoti, Preethi and Gummadi, Krishna P. and Weikum, Gerhard},
  year         = {2019},
  month        = apr,
  pages        = {1334–1345}
}

@article{Dastin_2018,
  title        = {Insight - Amazon scraps secret AI recruiting tool that showed bias against women},
  url          = {https://www.reuters.com/article/idUSKCN1MK0AG/},
  abstractnote = {Amazon.com Inc’s &lt;AMZN.O&gt; machine-learning specialists uncovered a big problem: their new recruiting engine did not like women.},
  journal      = {Reuters},
  author       = {Dastin, Jeffrey},
  year         = {2018},
  month        = oct,
  language     = {en-US}
}

@misc{datta_automated_2015,
  title      = {Automated {Experiments} on {Ad} {Privacy} {Settings}: {A} {Tale} of {Opacity}, {Choice}, and {Discrimination}},
  shorttitle = {Automated {Experiments} on {Ad} {Privacy} {Settings}},
  url        = {http://arxiv.org/abs/1408.6491},
  abstract   = {To partly address people's concerns over web tracking, Google has created the Ad Settings webpage to provide information about and some choice over the profiles Google creates on users. We present AdFisher, an automated tool that explores how user behaviors, Google's ads, and Ad Settings interact. AdFisher can run browser-based experiments and analyze data using machine learning and significance tests. Our tool uses a rigorous experimental design and statistical analysis to ensure the statistical soundness of our results. We use AdFisher to find that the Ad Settings was opaque about some features of a user's profile, that it does provide some choice on ads, and that these choices can lead to seemingly discriminatory ads. In particular, we found that visiting webpages associated with substance abuse changed the ads shown but not the settings page. We also found that setting the gender to female resulted in getting fewer instances of an ad related to high paying jobs than setting it to male. We cannot determine who caused these findings due to our limited visibility into the ad ecosystem, which includes Google, advertisers, websites, and users. Nevertheless, these results can form the starting point for deeper investigations by either the companies themselves or by regulatory bodies.},
  urldate    = {2024-04-14},
  publisher  = {arXiv},
  author     = {Datta, Amit and Tschantz, Michael Carl and Datta, Anupam},
  month      = mar,
  year       = {2015},
  note       = {arXiv:1408.6491 [cs]},
  keywords   = {Computer Science - Cryptography and Security},
  file       = {arXiv.org Snapshot:C\:\\Users\\rkal2\\Zotero\\storage\\HYXFYC8G\\1408.html:text/html;Full Text PDF:C\:\\Users\\rkal2\\Zotero\\storage\\J68XJ2MU\\Datta et al. - 2015 - Automated Experiments on Ad Privacy Settings A Ta.pdf:application/pdf}
}

@inproceedings{Kay_Matuszek_Munson_2015,
  address      = {New York, NY, USA},
  series       = {CHI ’15},
  title        = {Unequal Representation and Gender Stereotypes in Image Search Results for Occupations},
  isbn         = {978-1-4503-3145-6},
  url          = {https://dl.acm.org/doi/10.1145/2702123.2702520},
  doi          = {10.1145/2702123.2702520},
  abstractnote = {Information environments have the power to affect people’s perceptions and behaviors. In this paper, we present the results of studies in which we characterize the gender bias present in image search results for a variety of occupations. We experimentally evaluate the effects of bias in image search results on the images people choose to represent those careers and on people’s perceptions of the prevalence of men and women in each occupation. We find evidence for both stereotype exaggeration and systematic underrepresentation of women in search results. We also find that people rate search results higher when they are consistent with stereotypes for a career, and shifting the representation of gender in image search results can shift people’s perceptions about real-world distributions. We also discuss tensions between desires for high-quality results and broader societal goals for equality of representation in this space.},
  booktitle    = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
  publisher    = {Association for Computing Machinery},
  author       = {Kay and Matthew Matuszek and Cynthia Munson and Sean A.},
  year         = {2015},
  month        = apr,
  pages        = {3819–3828},
  collection   = {CHI ’15}
}

@article{Klare_Burge_Klontz_Vorder_Bruegge_Jain_2012,
  title        = {Face Recognition Performance: Role of Demographic Information},
  volume       = {7},
  issn         = {1556-6021},
  doi          = {10.1109/TIFS.2012.2214212},
  abstractnote = {This paper studies the influence of demographics on the performance of face recognition algorithms. The recognition accuracies of six different face recognition algorithms (three commercial, two nontrainable, and one trainable) are computed on a large scale gallery that is partitioned so that each partition consists entirely of specific demographic cohorts. Eight total cohorts are isolated based on gender (male and female), race/ethnicity (Black, White, and Hispanic), and age group (18–30, 30–50, and 50–70 years old). Experimental results demonstrate that both commercial and the nontrainable algorithms consistently have lower matching accuracies on the same cohorts (females, Blacks, and age group 18–30) than the remaining cohorts within their demographic. Additional experiments investigate the impact of the demographic distribution in the training set on the performance of a trainable face recognition algorithm. We show that the matching accuracy for race/ethnicity and age cohorts can be improved by training exclusively on that specific cohort. Operationally, this leads to a scenario, called dynamic face matcher selection, where multiple face recognition algorithms (each trained on different demographic cohorts) are available for a biometric system operator to select based on the demographic information extracted from a probe image. This procedure should lead to improved face recognition accuracy in many intelligence and law enforcement face recognition scenarios. Finally, we show that an alternative to dynamic face matcher selection is to train face recognition algorithms on datasets that are evenly distributed across demographics, as this approach offers consistently high accuracy across all cohorts.},
  number       = {6},
  journal      = {IEEE Transactions on Information Forensics and Security},
  author       = {Klare and Brendan F. Burge and Mark J. Klontz and Joshua C. Vorder Bruegge and Richard W. Jain and Anil K.},
  year         = {2012},
  month        = dec,
  pages        = {1789–1801}
}

@misc{Machine_Translation_Gendered_Innovations,
  url = {https://genderedinnovations.stanford.edu/case-studies/nlp.html#tabs-2}
}

@inproceedings{Dombrowski_Harmon_Fox_2016,
  address   = {Brisbane QLD Australia},
  title     = {Social Justice-Oriented Interaction Design: Outlining Key Design Strategies and Commitments},
  isbn      = {978-1-4503-4031-1},
  url       = {https://dl.acm.org/doi/10.1145/2901790.2901861},
  doi       = {10.1145/2901790.2901861},
  booktitle = {Proceedings of the 2016 ACM Conference on Designing Interactive Systems},
  publisher = {ACM},
  author    = {Dombrowski and Lynn Harmon and Ellie Fox and Sarah},
  year      = {2016},
  month     = jun,
  pages     = {656–671},
  language  = {en}
}

@book{Kraut_Resnick_2012,
  title        = {Building Successful Online Communities: Evidence-Based Social Design},
  isbn         = {978-0-262-29831-5},
  url          = {https://direct.mit.edu/books/book/2912/Building-Successful-Online-CommunitiesEvidence},
  doi          = {10.7551/mitpress/8472.001.0001},
  abstractnote = {How insights from the social sciences, including social psychology and economics, can improve the design of online communities.Online communities are among the},
  publisher    = {The MIT Press},
  author       = {Kraut and Robert E. Resnick and Paul},
  year         = {2012},
  month        = mar,
  language     = {en}
}

@article{Zytko_Furlo_Aljasim_2021,
  title        = {Human-AI Interaction for User Safety in Social Matching Apps: Involving Marginalized Users in Design},
  abstractnote = {In this position paper we intend to advocate for participatory design methods and mobile social matching apps as ripe contexts for exploring novel human-AI interactions that benefit marginalized groups. Mobile social matching apps like Tinder and Bumble use AI to introduce users to each other for rapid face-toface meetings. These user discoveries and subsequent interactions pose disproportionate risk of sexual violence and other harms to marginalized user demographics, specifically women and the LGBTQIA+ community. We want to extend the role of AI in these apps to keep users safe while they interact with strangers across online and offline modalities. To do this, we are using participatory design methods to empower women and LGBTQIA+ individuals to envision future human-AI interactions that prioritize their safety during social matching app-use. In one study, stakeholders identifying as LGBTQIA+ or women are redesigning dating apps to mediate exchange of sexual consent and therefore mitigate sexual violence. In the other study, women are designing multi-purpose, opportunistic social matching apps that foreground women’s safety.},
  author       = {Zytko and Douglas Furlo and Nicholas Aljasim and Hanan},
  year         = {2021},
  language     = {en}
}

@article{Yang_2021,
  title        = {A technoethical exploration of online dating algorithms: A systematic literature review},
  url          = {http://ruor.uottawa.ca/handle/10393/42330},
  abstractnote = {While algorithmic online dating has been increasingly used by singles worldwide to build romantic relationships, a growing number of studies focus on social impacts and ethical concerns of online dating algorithms. To comprehensively examine online dating algorithms from a social and ethical perspective, this researcher conducted a systematic literature review and a technoethical assessment of online dating algorithms’ social influences and ethical innovations. This work identified seven major social and ethical issues around online dating algorithms, including personal development, culture, social equality, business, political concerns, ethics and morals, and privacy. The technoethical assessment also calls for 1) more public awareness of online dating algorithms’ influential potential, and 2) online dating platforms’ responsible design, use and regulation of online dating algorithms. This study fills the knowledge gap between technology and communication studies concerning algorithmic governance in online dating and contributes strategic information on ethical innovations in online dating algorithms’ design. 
                  Keywords: algorithms, online dating, technoethics, systematic literature review, social constructionism},
  note         = {Accepted: 2021-06-24T18:04:59Z},
  author       = {Yang and Kexin},
  year         = {2021},
  language     = {en}
}

@article{Tyson_Perta_Haddadi_Seto_2016,
  title        = {A First Look at User Activity on Tinder},
  url          = {http://arxiv.org/abs/1607.01952},
  abstractnote = {Mobile dating apps have become a popular means to meet potential partners. Although several exist, one recent addition stands out amongst all others. Tinder presents its users with pictures of people geographically nearby, whom they can either like or dislike based on first impressions. If two users like each other, they are allowed to initiate a conversation via the chat feature. In this paper we use a set of curated profiles to explore the behaviour of men and women in Tinder. We reveal differences between the way men and women interact with the app, highlighting the strategies employed. Women attain large numbers of matches rapidly, whilst men only slowly accumulate matches. To expand on our findings, we collect survey data to understand user intentions on Tinder. Most notably, our results indicate that a little effort in grooming profiles, especially for male users, goes a long way in attracting attention.},
  note         = {arXiv:1607.01952 [cs]},
  number       = {arXiv:1607.01952},
  publisher    = {arXiv},
  author       = {Tyson and Gareth Perta and Vasile C. Haddadi and Hamed Seto and Michael C.},
  year         = {2016},
  month        = jul
}

@inproceedings{Mislove_Viswanath_Gummadi_Druschel_2010,
  address   = {New York New York USA},
  title     = {You are who you know: inferring user profiles in online social networks},
  isbn      = {978-1-60558-889-6},
  url       = {https://dl.acm.org/doi/10.1145/1718487.1718519},
  doi       = {10.1145/1718487.1718519},
  booktitle = {Proceedings of the third ACM international conference on Web search and data mining},
  publisher = {ACM},
  author    = {Mislove and Alan Viswanath and Bimal Gummadi and Krishna P. Druschel and Peter},
  year      = {2010},
  month     = feb,
  pages     = {251–260},
  language  = {en}
}

@article{Elovici_Fire_Herzberg_Shulman_2014,
  title        = {Ethical Considerations when Employing Fake Identities in Online Social Networks for Research},
  volume       = {20},
  issn         = {1471-5546},
  doi          = {10.1007/s11948-013-9473-0},
  abstractnote = {Online social networks (OSNs) have rapidly become a prominent and widely used service, offering a wealth of personal and sensitive information with significant security and privacy implications. Hence, OSNs are also an important—and popular—subject for research. To perform research based on real-life evidence, however, researchers may need to access OSN data, such as texts and files uploaded by users and connections among users. This raises significant ethical problems. Currently, there are no clear ethical guidelines, and researchers may end up (unintentionally) performing ethically questionable research, sometimes even when more ethical research alternatives exist. For example, several studies have employed “fake identities” to collect data from OSNs, but fake identities may be used for attacks and are considered a security issue. Is it legitimate to use fake identities for studying OSNs or for collecting OSN data for research? We present a taxonomy of the ethical challenges facing researchers of OSNs and compare different approaches. We demonstrate how ethical considerations have been taken into account in previous studies that used fake identities. In addition, several possible approaches are offered to reduce or avoid ethical misconducts. We hope this work will stimulate the development and use of ethical practices and methods in the research of online social networks.},
  number       = {4},
  journal      = {Science and Engineering Ethics},
  author       = {Elovici and Yuval Fire and Michael Herzberg and Amir Shulman and Haya},
  year         = {2014},
  month        = dec,
  pages        = {1027–1043},
  language     = {en}
}

@article{Jernigan_Mistree_2009,
  title        = {Gaydar: Facebook friendships expose sexual orientation},
  rights       = {Copyright (c)},
  issn         = {1396-0466},
  url          = {https://firstmonday.org/ojs/index.php/fm/article/view/2611},
  doi          = {10.5210/fm.v14i10.2611},
  abstractnote = {Public information about one’s coworkers, friends, family, and acquaintances, as well as one’s associations with them, implicitly reveals private information.  Social-networking websites, e-mail, instant messaging, telephone, and VoIP are all technologies steeped in network data—data relating one person to another.  Network data shifts the locus of information control away from individuals, as the individual’s traditional and absolute discretion is replaced by that of his social-network.  Our research demonstrates a method for accurately predicting the sexual orientation of Facebook users by analyzing friendship associations.  After analyzing 4,080 Facebook profiles from the MIT network, we determined that the percentage of a given user’s friends who self-identify as gay male is strongly correlated with the sexual orientation of that user, and we developed a logistic regression classifier with strong predictive power.  Although we studied Facebook friendship ties, network data is pervasive in the broader context of computer-mediated communication, raising significant privacy issues for communication technologies to which there are no neat solutions.},
  journal      = {First Monday},
  author       = {Jernigan and Carter Mistree and Behram F. T.},
  year         = {2009},
  month        = sep,
  language     = {en}
}

@article{Petterson_Wrightson_Vasey_2017,
  title        = {Recalled Gendered Behavior in Childhood: A Comparison of Androphilic Men, Gynephilic Men, and Androphilic Women in Japan},
  volume       = {46},
  issn         = {1573-2800},
  doi          = {10.1007/s10508-016-0781-8},
  abstractnote = {The current study tested the hypothesis that men who are androphilic (sexually attracted to adult men) in a non-Western, developed country—Japan—would recall engaging in more female-typical behavior, and less male-typical behavior, in childhood, compared to men who are gynephilic (sexually attracted to adult women). Androphilic men, androphilic women, and gynephilic men (N = 302) responded to the Female-Typical Behavior Subscale and the Male-Typical Behavior Subscale of the Childhood Gender Identity Scale, which asked participants to recall their childhood behavior. Results indicated that gynephilic men scored highest on the Male-Typical Behavior Subscale and lowest on the Female-Typical Behavior Subscale. Androphilic women scored the highest on the Female-Typical Behavior Subscale and lowest on the Male-Typical Behavior Subscale. Androphilic men scored intermediately for both the Male- and Female-Typical Behavior Subscales. The results supported the hypothesis that Japanese androphilic men would recall greater gender-nonconforming childhood behavior compared to gynephilic men. These results further reinforce the conclusion that childhood gender-nonconforming behavior is a cross-culturally universal aspect of psychosexual life course development in androphilic men. We discuss why this may be the case, as well as why cross-cultural variation occurs in the magnitude with which recalled childhood gender nonconformity is reported by androphilic males.},
  number       = {1},
  journal      = {Archives of Sexual Behavior},
  author       = {Petterson and Lanna J. Wrightson and Chelsea R. Vasey and Paul L.},
  year         = {2017},
  month        = jan,
  pages        = {119–127},
  language     = {en}
}

@article{Snowden_Fitton_McKinnon_Gray_2020,
  title        = {Sexual Attraction to Both Genders in Ambiphilic Men: Evidence from Implicit Cognitions},
  volume       = {49},
  issn         = {1573-2800},
  doi          = {10.1007/s10508-019-01552-6},
  abstractnote = {Ambiphilic (or bisexual) men describe feelings of sexual attraction to both men and women. However, physiological measures of arousal have failed to show a consistent pattern of arousal to both genders. We measured men’s automatic associations between the concept of sex (represented by words) and the concepts of men versus women (represented by images) via the Implicit Association Test (IAT) and a priming task. On the IAT, gynephilic men (N = 32) were faster for women-sex pairings, androphilic men (N = 18) were faster for men-sex pairings, while ambiphilic men (N = 20) showed no bias toward either gender. We then isolated the concepts of “men” and “women” by comparing them separately against neutral images. In contrast to both the gynephilic or androphilic men, ambiphilic men showed sexual associations to both men and women. On the priming task, ambiphilic men showed faster responses to sex words, but slower responses to not-sex words, when primed with pictures of either men or women compared to when primed by neutral images. The results from all the experimental tasks suggest that ambiphilic men have a pattern of sexual association that is different from both gynephilic and androphilic men and represents a sexual attraction to both men and women.},
  number       = {2},
  journal      = {Archives of Sexual Behavior},
  author       = {Snowden and Robert J. Fitton and Ellen McKinnon and Aimee Gray and Nicola S.},
  year         = {2020},
  month        = feb,
  pages        = {503–515},
  language     = {en}
}

@inbook{Vasey_VanderLaan_2014,
  address      = {New York, NY},
  title        = {Evolutionary Perspectives on Male Androphilia in Humans},
  isbn         = {978-1-4939-0314-6},
  url          = {https://doi.org/10.1007/978-1-4939-0314-6_19},
  doi          = {10.1007/978-1-4939-0314-6_19},
  abstractnote = {Androphilia refers to predominant sexual attraction and arousal to adult males, whereas gynephilia refers to predominant sexual attraction and arousal to adult females. The manner in which male androphilia is expressed varies cross-culturally. Sex-gender congruent male androphiles occupy the gender role typical of their sex, behave in a relatively masculine manner, and identify as “men.” In contrast, transgendered male androphiles often behave in a highly effeminate manner and identify as neither “men” nor “women.” Both forms are characterized by many of the same biodemographic and developmental correlates, which indicates that they share a common etiological basis despite being superficially different in appearance. Evidence suggests that the ancestral form of male androphilia was likely the transgendered form. Male androphilia represents an evolutionary paradox because (1) it appears to have a genetic component, yet (2) it compromises reproduction, and (3) archaeological evidence indicates that male-male sexual behavior has persisted for millennia. Two hypotheses that purport to explain the evolution of male androphilia have garnered support: the Kin Selection Hypothesis and the Sexually Antagonistic Gene Hypothesis. Research has repeatedly furnished support for the Kin Selection Hypothesis in Samoa where transgendered male androphiles (fa’afafine) exhibit elevated avuncular tendencies compared to women and gynephilic men. Tests of the Sexually Antagonistic Gene Hypothesis have been conducted in diverse populations of transgendered and sex-gender congruent male androphiles. Overall, these tests indicate that the female kin of male androphiles produce more offspring than those of male gynephiles.},
  booktitle    = {Evolutionary Perspectives on Human Sexual Psychology and Behavior},
  publisher    = {Springer},
  author       = {Vasey and Paul L. VanderLaan and Doug P.},
  editor       = {Weekes-Shackelford, Viviana A. and Shackelford, Todd K.},
  year         = {2014},
  pages        = {369–391},
  language     = {en}
}

@book{Costanza-Chock_2020,
  title        = {Design Justice: Community-Led Practices to Build the Worlds We Need},
  isbn         = {978-0-262-35686-2},
  url          = {https://direct.mit.edu/books/oa-monograph/4605/Design-JusticeCommunity-Led-Practices-to-Build-the},
  doi          = {10.7551/mitpress/12255.001.0001},
  abstractnote = {An exploration of how design might be led by marginalized communities, dismantle structural inequality, and advance collective liberation and ecological su},
  publisher    = {The MIT Press},
  author       = {Costanza-Chock and Sasha},
  year         = {2020},
  month        = mar,
  language     = {en}
}

@book{Eubanks_2018,
  address      = {USA},
  title        = {Automating Inequality: How High-Tech Tools Profile, Police, and Punish the Poor},
  isbn         = {978-1-250-07431-7},
  abstractnote = {Naomi Klein: “This book is downright scary.”Ethan Zuckerman, MIT: “Should be required reading.”Dorothy Roberts, author of Killing the Black Body: “A must-read.”Astra Taylor, author of The People’s Platform: “The single most important book about technology you will read this year.”Cory Doctorow: “Indispensable.”A powerful investigative look at data-based discriminationand how technology affects civil and human rights and economic equity The State of Indiana denies one million applications for healthcare, foodstamps and cash benefits in three yearsbecause a new computer system interprets any mistake as failure to cooperate. In Los Angeles, an algorithm calculates the comparative vulnerability of tens of thousands of homeless people in order to prioritize them for an inadequate pool of housing resources. In Pittsburgh, a child welfare agency uses a statistical model to try to predict which children might be future victims of abuse or neglect. Since the dawn of the digital age, decision-making in finance, employment, politics, health and human services has undergone revolutionary change. Today, automated systemsrather than humanscontrol which neighborhoods get policed, which families attain needed resources, and who is investigated for fraud. While we all live under this new regime of data, the most invasive and punitive systems are aimed at the poor. In Automating Inequality, Virginia Eubanks systematically investigates the impacts of data mining, policy algorithms, and predictive risk models on poor and working-class people in America. The book is full of heart-wrenching and eye-opening stories, from a woman in Indiana whose benefits are literally cut off as she lays dying to a family in Pennsylvania in daily fear of losing their daughter because they fit a certain statistical profile. The U.S. has always used its most cutting-edge science and technology to contain, investigate, discipline and punish the destitute. Like the county poorhouse and scientific charity before them, digital tracking and automated decision-making hide poverty from the middle-class public and give the nation the ethical distance it needs to make inhumane choices: which families get food and which starve, who has housing and who remains homeless, and which families are broken up by the state. In the process, they weaken democracy and betray our most cherished national values. This deeply researched and passionate book could not be more timely.},
  publisher    = {St. Martin’s Press, Inc.},
  author       = {Eubanks and Virginia},
  year         = {2018}
}
@book{ONeil_2016,
  address      = {USA},
  title        = {Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy},
  isbn         = {978-0-553-41881-1},
  abstractnote = {A former Wall Street quant sounds an alarm on the mathematical models that pervade modern life and threaten to rip apart our social fabricWe live in the age of the algorithm. Increasingly, the decisions that affect our liveswhere we go to school, whether we get a car loan, how much we pay for health insuranceare being made not by humans, but by mathematical models. In theory, this should lead to greater fairness: Everyone is judged according to the same rules, and bias is eliminated. But as Cathy ONeil reveals in this urgent and necessary book, the opposite is true. The models being used today are opaque, unregulated, and uncontestable, even when theyre wrong. Most troubling, they reinforce discrimination: If a poor student cant get a loan because a lending model deems him too risky (by virtue of his zip code), hes then cut off from the kind of education that could pull him out of poverty, and a vicious spiral ensues. Models are propping up the lucky and punishing the downtrodden, creating a toxic cocktail for democracy. Welcome to the dark side of Big Data. Tracing the arc of a persons life, ONeil exposes the black box models that shape our future, both as individuals and as a society. These weapons of math destruction score teachers and students, sort rsums, grant (or deny) loans, evaluate workers, target voters, set parole, and monitor our health. ONeil calls on modelers to take more responsibility for their algorithms and on policy makers to regulate their use. But in the end, its up to us to become more savvy about the models that govern our lives. This important book empowers us to ask the tough questions, uncover the truth, and demand change.},
  publisher    = {Crown Publishing Group},
  author       = {O’Neil and Cathy},
  year         = {2016},
  month        = aug
}

@book{Benjamin_2019,
  title        = {Race After Technology: Abolitionist Tools for the New Jim Code},
  isbn         = {978-1-5095-2643-7},
  abstractnote = {From everyday apps to complex algorithms, Ruha Benjamin cuts through tech-industry hype to understand how emerging technologies can reinforce White supremacy and deepen social inequity. Benjamin argues that automation, far from being a sinister story of racist programmers scheming on the dark web, has the potential to hide, speed up, and deepen discrimination while appearing neutral and even benevolent when compared to the racism of a previous era. Presenting the concept of the “New Jim Code,” she shows how a range of discriminatory designs encode inequity by explicitly amplifying racial hierarchies; by ignoring but thereby replicating social divisions; or by aiming to fix racial bias but ultimately doing quite the opposite. Moreover, she makes a compelling case for race itself as a kind of technology, designed to stratify and sanctify social injustice in the architecture of everyday life. This illuminating guide provides conceptual tools for decoding tech promises with sociologically informed skepticism. In doing so, it challenges us to question not only the technologies we are sold but also the ones we ourselves manufacture. Visit the book’s free Discussion Guide: www.dropbox.com},
  publisher    = {John Wiley and Sons},
  author       = {Benjamin and Ruha},
  year         = {2019},
  month        = jul,
  language     = {en}
}
@book{Noble_2018,
  title        = {Algorithms of Oppression: How Search Engines Reinforce Racism},
  isbn         = {978-1-4798-4994-9},
  url          = {http://www.jstor.org/stable/j.ctt1pwt9w5},
  doi          = {10.2307/j.ctt1pwt9w5},
  abstractnote = {<strong>A revealing look at how negative biases against women of color are embedded in search engine results and algorithms</strong> Run a Google search for “black girls”-what will you find? “Big
                  Booty” and other sexually explicit terms are likely to come up as top search terms. But, if you type in “white girls,” the results
                  are radically different. The suggested porn sites and un-moderated discussions about “why black women are so sassy” or “why black
                  women are so angry” presents a disturbing portrait of black
                  womanhood in modern society. In <em>Algorithms of Oppression</em>, Safiya Umoja Noble challenges the idea that search engines like
                  Google offer an equal playing field for all forms of ideas,
                  identities, and activities. Data discrimination is a real social
                  problem; Noble argues that the combination of private interests in promoting certain sites, along with the monopoly status of a
                  relatively small number of Internet search engines, leads to a
                  biased set of search algorithms that privilege whiteness and
                  discriminate against people of color, specifically women of color. Through an analysis of textual and media searches as well as
                  extensive research on paid online advertising, Noble exposes a
                  culture of racism and sexism in the way discoverability is created online. As search engines and their related companies grow in
                  importance-operating as a source for email, a major vehicle for
                  primary and secondary school learning, and beyond-understanding and reversing these disquieting trends and discriminatory practices is of utmost importance. An original, surprising and, at times,
                  disturbing account of bias on the internet, <em>Algorithms of
                  Oppression</em> contributes to our understanding of how racism is created, maintained, and disseminated in the 21st century.},
  publisher    = {NYU Press},
  author       = {Noble and Safiya Umoja},
  year         = {2018}
}

@book{Creswell_2009,
  address      = {Thousand Oaks,  CA,  US},
  series       = {Research design: Qualitative, quantitative, and mixed methods approaches, 3rd ed.},
  title        = {Research design: Qualitative, quantitative, and mixed methods approaches, 3rd ed.},
  isbn         = {978-1-4129-6557-6},
  abstractnote = {The Third Edition of John W. Creswell’s best-selling Research Design enables readers to compare three approaches to research—qualitative, quantitative, and mixed methods—in a single research methods text. The book examines these methodologies side by side within the process of research, from the beginning steps of philosophical assumptions to the writing and presenting of research. Written in a user-friendly manner, this text showcases ideas in a system of scaffolds so that the reader understands concepts from the simple to the complex. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  publisher    = {Sage Publications, Inc},
  author       = {Creswell and John W.},
  year         = {2009},
  pages        = {xxix, 260},
  collection   = {Research design: Qualitative, quantitative, and mixed methods approaches, 3rd ed.}
}

 @book{PASQUALE_2015,
  title        = {The Black Box Society},
  isbn         = {978-0-674-36827-9},
  url          = {http://www.jstor.org/stable/j.ctt13x0hch},
  abstractnote = {Every day, corporations are connecting the dots about our personal behavior—silently scrutinizing clues left behind by our work habits and Internet use. But who connects the dots about what firms are doing with all this information? Frank Pasquale exposes how powerful interests abuse secrecy for profit and explains ways to rein them in.},
  publisher    = {Harvard University Press},
  author       = {PASQUALE and FRANK},
  year         = {2015}
}

@article{Crawford_Calo_2016,
  title        = {There is a blind spot in AI research},
  volume       = {538},
  issn         = {1476-4687},
  doi          = {10.1038/538311a},
  abstractnote = {Fears about the future impacts of artificial intelligence are distracting researchers from the real risks of deployed systems, argue Kate Crawford and Ryan Calo.},
  number       = {7625},
  journal      = {Nature},
  author       = {Crawford and Kate Calo and Ryan},
  year         = {2016},
  month        = oct,
  pages        = {311–313}
}

@article{Kaminski_2019,
  title        = {The Right to Explanation, Explained},
  url          = {https://lawcat.berkeley.edu/record/1128984},
  doi          = {10.15779/Z38TD9N83H},
  abstractnote = {Many have called for algorithmic accountability: laws governing decision-making by complex algorithms, or artificial intelligence (AI). The EU’s General Data Protection Regulation (GDPR) now establishes exactly this. The recent debate over the “right to explanation” (a right to information about individual decisions made by algorithms) has obscured the significant algorithmic accountability regime established by the GDPR. The GDPR’s provisions on algorithmic accountability, which include a right to explanation, have the potential to be broader, stronger, and deeper than the requirements of the preceding Data Protection Directive. This Article clarifies, including for a U.S. audience, what the GDPR requires.},
  publisher    = {[object Object]},
  author       = {Kaminski and Margot E.},
  year         = {2019},
  language     = {en}
}

@article{Linden_2020,
  title           = {Automating the News: How Algorithms are Rewriting the Media},
  rights          = {© 2020 Mass Communication & Society Division of the Association for Education in Journalism and Mass Communication},
  issn            = {1520-5436},
  archivelocation = {world},
  url             = {https://www.tandfonline.com/doi/full/10.1080/15205436.2020.1783887},
  abstractnote    = {Few persons are better equipped than Nick Diakopoulos to write a book about the exciting algorithmic development in newsrooms that transforms the work of journalists in so many ways, some negative,...},
  journal         = {Mass Communication and Society},
  publisher       = {Routledge},
  author          = {Lindén and Reviewed by Carl-Gustav},
  year            = {2020},
  month           = nov,
  language        = {EN}
}
@article{Mittelstadt_2016,
  author   = {Brent Daniel Mittelstadt and Patrick Allo and Mariarosaria Taddeo and Sandra Wachter and Luciano Floridi},
  title    = {The ethics of algorithms: Mapping the debate},
  journal  = {Big Data \& Society},
  volume   = {3},
  number   = {2},
  pages    = {2053951716679679},
  year     = {2016},
  doi      = {10.1177/2053951716679679},
  url      = { 
              
              https://doi.org/10.1177/2053951716679679
              
              
              
              },
  eprint   = { 
              
              https://doi.org/10.1177/2053951716679679
              
              
              
              },
  abstract = { In information societies, operations, decisions and choices previously left to humans are increasingly delegated to algorithms, which may advise, if not decide, about how data should be interpreted and what actions should be taken as a result. More and more often, algorithms mediate social processes, business transactions, governmental decisions, and how we perceive, understand, and interact among ourselves and with the environment. Gaps between the design and operation of algorithms and our understanding of their ethical implications can have severe consequences affecting individuals as well as groups and whole societies. This paper makes three contributions to clarify the ethical importance of algorithmic mediation. It provides a prescriptive map to organise the debate. It reviews the current discussion of ethical aspects of algorithms. And it assesses the available literature in order to identify areas requiring further work to develop the ethics of algorithms. }
}

@misc{heidivellastarr_2022,
  title        = {Dating in the age of AI: would you let an algorithm choose your partner?},
  url          = {https://heidivella.com/2022/01/03/dating-in-the-age-of-ai-would-you-let-an-algorithm-choose-your-partner/},
  abstractnote = {As people continue to rely more and more on computer intelligence to shepherd them through life, delegating the oftentimes inexplicable task of matchmaking to the problem-solving altar of AI is a n…},
  journal      = {Heidi Vella},
  author       = {heidivellastarr},
  year         = {2022},
  month        = jan,
  language     = {en}
}



