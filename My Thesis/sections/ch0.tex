The advent of online dating platforms, spearheaded by technological advancements and changing societal norms, has significantly transformed the landscape of romantic and interpersonal relationships. Among these platforms, Bumble has emerged as a frontrunner in India, promoting itself as a site of progressive values with its unique feature allowing only women to initiate conversations [(Bumble, n.d.-b)]. This shift towards digital intimacy is underpinned by a growing internet user base in India, projected to reach 1.3 billion in 2023 [(Statista, 2023)], creating an expansive arena for online dating applications.

The promise of these platforms, however, is mired in complexities concerning algorithmic biases. Despite their potential for facilitating diverse and inclusive interactions, the algorithms driving these platforms often replicate and amplify societal biases. Such biases are not inherent to the algorithms but stem from the data on which they are trained, reflecting historical and cultural prejudices [(Davidson et al., 2019) (Raghavan et al., 2019)]. In the case of Bumble, the platform's algorithm learns from user behavior to make match recommendations, a process that, while seemingly neutral, can inadvertently perpetuate discrimination based on gender and other social identities.

The consequences of these biases extend beyond the digital space, affecting users' self-perception and interaction with others. For individuals of non-binary genders, these biases can result in a reduced visibility and misrepresentation, reinforcing existing gender norms and excluding them from fully participating in the online dating experience [(Bivens & Hoque, 2018) (MacLeod & McArthur, 2019)]. The "Elo Score" system, speculated to be used by Bumble, illustrates this issue by ranking desirability based on opaque factors, potentially marginalizing users who do not conform to mainstream criteria of attractiveness [(Carr, 2016)].

Furthermore, the role of dating apps in shaping social norms and behaviors is increasingly acknowledged, with platforms like Bumble influencing not just romantic interactions but also broader societal perceptions of gender and sexuality [(Das, 2019) (Forbes, 2020)]. The integration of features aimed at inclusivity, such as pronoun selection and guides for queer dating, highlights Bumble's efforts towards creating a safer and more welcoming environment for all users [(Bumble, n.d.-a) (Bumble, n.d.-b)]. Yet, the persistence of algorithmic biases underscores the challenges of reconciling technological innovation with the need for social justice and equality.

The study of gender disparities in Bumble's match recommendations thus sits at the intersection of technology, culture, and social justice. It offers a critical lens through which to examine the implications of algorithmic decision-making on social identities, highlighting the urgent need for more inclusive and equitable design practices in the realm of online dating.